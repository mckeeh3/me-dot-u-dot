# =================================================================================
# All model configurations must be named ai-agent-model-<unique-model-key-name>
# DO NOT use '.' (period) in model names
# =================================================================================

# =================================================================================
# OpenAI models
# =================================================================================

ai-agent-model-gpt-5 {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-5"
  base-url = "https://api.openai.com/v1"
  # For GPT-5 is not configurable and is always set to the default value 1
  temperature = 1.0
  # For GPT-5 is not configurable and is always set to the default value 1
  top-p = 1.0
  max-tokens = 200000
  max-completion-tokens = 200000
}

ai-agent-model-gpt-5-mini {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-5-mini"
  base-url = "https://api.openai.com/v1"
  # For GPT-5 is not configurable and is always set to the default value 1
  temperature = 1.0
  # For GPT-5 is not configurable and is always set to the default value 1
  top-p = 1.0
  max-tokens = 200000
  max-completion-tokens = 200000
}

ai-agent-model-gpt-4_1 {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-4.1"
  base-url = "https://api.openai.com/v1"
  temperature = 1.0
  top-p = 1.0
  max-tokens = 32768
}

ai-agent-model-gpt-4_1-mini {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-4.1-mini"
  base-url = "https://api.openai.com/v1"
  temperature = 1.0
  top-p = 1.0
  max-tokens = 200000
}

ai-agent-model-gpt-4o {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-4o"
  base-url = "https://api.openai.com/v1"
  temperature = 1.0
  top-p = 1.0
  max-tokens = 16384
}

ai-agent-model-gpt-4o-mini {
  provider = "openai"
  api-key = ""
  api-key = ${?OPENAI_API_KEY}
  model-name = "gpt-4o-mini"
  base-url = "https://api.openai.com/v1"
  temperature = 1.0
  top-p = 1.0
  max-tokens = 16384
}

# =================================================================================
# Google AI Gemini models
# =================================================================================

ai-agent-model-gemini-2_5-flash-lite {
  # The provider name, must be "googleai-gemini"
  provider = "googleai-gemini"
  # The API key for authentication with Google AI Gemini's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?GOOGLE_AI_GEMINI_API_KEY}
  # The name of the model to use, e.g. "gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro" or "gemini-1.0-pro"
  model-name = "gemini-2.5-flash-lite"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Maximum number of tokens to generate (-1 for model default)
  max-output-tokens = -1
}

ai-agent-model-gemini-2_5-flash {
  # The provider name, must be "googleai-gemini"
  provider = "googleai-gemini"
  # The API key for authentication with Google AI Gemini's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?GOOGLE_AI_GEMINI_API_KEY}
  # The name of the model to use, e.g. "gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro" or "gemini-1.0-pro"
  model-name = "gemini-2.5-flash"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Maximum number of tokens to generate (-1 for model default)
  max-output-tokens = -1
}

ai-agent-model-gemini-2_5-pro {
  # The provider name, must be "googleai-gemini"
  provider = "googleai-gemini"
  # The API key for authentication with Google AI Gemini's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?GOOGLE_AI_GEMINI_API_KEY}
  # The name of the model to use, e.g. "gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro" or "gemini-1.0-pro"
  model-name = "gemini-2.5-pro"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Maximum number of tokens to generate (-1 for model default)
  max-output-tokens = -1
}

# =================================================================================
# Anthropic models
# =================================================================================

ai-agent-model-claude-sonnet-4-20250514 {
  # The provider name, must be "anthropic"
  provider = "anthropic"
  # The API key for authentication with Anthropic's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?ANTHROPIC_API_KEY}
  # The name of the model to use, e.g. "claude-2" or "claude-instant-1"
  model-name = "claude-sonnet-4-20250514"
  # Optional base URL override for the Anthropic API
  base-url = "https://api.anthropic.com/v1"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Top-k sampling parameter (-1 to disable).
  # Top-k sampling limits text generation to only the k most probable
  # tokens at each step, discarding all other possibilities regardless
  # of their probability. It provides a simpler way to control randomness,
  # smaller k values (like 10) produce more focused outputs while larger
  # values (like 50) allow for more diversity.
  top-k = -1
  # Maximum number of tokens to generate (-1 for model default)
  max-tokens = -1
}

ai-agent-model-claude-opus-4-20250514 {
  # The provider name, must be "anthropic"
  provider = "anthropic"
  # The API key for authentication with Anthropic's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?ANTHROPIC_API_KEY}
  # The name of the model to use, e.g. "claude-2" or "claude-instant-1"
  model-name = "claude-opus-4-20250514"
  # Optional base URL override for the Anthropic API
  base-url = "https://api.anthropic.com/v1"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Top-k sampling parameter (-1 to disable).
  # Top-k sampling limits text generation to only the k most probable
  # tokens at each step, discarding all other possibilities regardless
  # of their probability. It provides a simpler way to control randomness,
  # smaller k values (like 10) produce more focused outputs while larger
  # values (like 50) allow for more diversity.
  top-k = -1
  # Maximum number of tokens to generate (-1 for model default)
  max-tokens = -1
}

ai-agent-model-claude-opus-4_1-20250805 {
  # The provider name, must be "anthropic"
  provider = "anthropic"
  # The API key for authentication with Anthropic's API
  api-key = ""
  # Environment variable override for the API key
  api-key = ${?ANTHROPIC_API_KEY}
  # The name of the model to use, e.g. "claude-2" or "claude-instant-1"
  model-name = "claude-opus-4.1-20250805"
  # Optional base URL override for the Anthropic API
  base-url = "https://api.anthropic.com/v1"
  # Controls randomness in the model's output (0.0 to 1.0)
  temperature = NaN
  # Nucleus sampling parameter (0.0 to 1.0). Controls text generation by
  # only considering the most likely tokens whose cumulative probability
  # exceeds the threshold value. It helps balance between diversity and
  # quality of outputs—lower values (like 0.3) produce more focused,
  # predictable text while higher values (like 0.9) allow more creativity
  # and variation.
  top-p = NaN
  # Top-k sampling parameter (-1 to disable).
  # Top-k sampling limits text generation to only the k most probable
  # tokens at each step, discarding all other possibilities regardless
  # of their probability. It provides a simpler way to control randomness,
  # smaller k values (like 10) produce more focused outputs while larger
  # values (like 50) allow for more diversity.
  top-k = -1
  # Maximum number of tokens to generate (-1 for model default)
  max-tokens = -1
}
